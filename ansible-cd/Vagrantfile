# -*- mode: ruby -*-
# vi: set ft=ruby :

# start extra disks
# ref: https://sleeplessbeastie.eu/2021/05/10/how-to-define-multiple-disks-inside-vagrant-using-virtualbox-provider/

# ###############################################################
# require 'fileutils'

# # file operations needs to be relative to this file
# VAGRANT_ROOT = File.dirname(File.expand_path(__FILE__))

# # directory that will contain VDI files
# VAGRANT_DISKS_DIRECTORY = "disks"

# # controller definition
# VAGRANT_CONTROLLER_NAME = "Virtual I/O Device SCSI controller"
# VAGRANT_CONTROLLER_TYPE = "virtio-scsi"

# # define disks
# # The format is filename, size (GB), port (see controller docs)
# local_disks = [
#   { :filename => "disk1", :size => 1, :port => 5 },
#   { :filename => "disk2", :size => 2, :port => 6 },
#   { :filename => "disk3", :size => 1, :port => 25 }
# ]
# # end disks CONFIG
# #############################################

VAGRANTFILE_API_VERSION = "2"
# VAGRANT_EXPERIMENTAL="disks"
Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|
  # General Vagrant VM configuration.e
  config.vm.box = "bento/ubuntu-22.04"

  # ###################
  # # START DISKS CREATION
  # disks_directory = File.join(VAGRANT_ROOT, VAGRANT_DISKS_DIRECTORY)
  # disks_directory = File.join(VAGRANT_ROOT, VAGRANT_DISKS_DIRECTORY)

  # # create disks before "up" action
  # config.trigger.before :up do |trigger|
  #   trigger.name = "Create disks"
  #   trigger.ruby do
  #     unless File.directory?(disks_directory)
  #       FileUtils.mkdir_p(disks_directory)
  #     end
  #     local_disks.each do |local_disk|
  #       local_disk_filename = File.join(disks_directory, "#{local_disk[:filename]}.vdi")
  #       unless File.exist?(local_disk_filename)
  #         puts "Creating \"#{local_disk[:filename]}\" disk"
  #         system("vboxmanage createmedium --filename #{local_disk_filename} --size #{local_disk[:size] * 1024} --format VDI")
  #       end
  #     end
  #   end
  # end

  # # create storage controller on first run
  # unless File.directory?(disks_directory)
  #   config.vm.provider "virtualbox" do |storage_provider|
  #     storage_provider.customize ["storagectl", :id, "--name", VAGRANT_CONTROLLER_NAME, "--add", VAGRANT_CONTROLLER_TYPE, '--hostiocache', 'off']
  #   end
  # end

  # # attach storage devices
  # config.vm.provider "virtualbox" do |storage_provider|
  #   local_disks.each do |local_disk|
  #     local_disk_filename = File.join(disks_directory, "#{local_disk[:filename]}.vdi")
  #     unless File.exist?(local_disk_filename)
  #       storage_provider.customize ['storageattach', :id, '--storagectl', VAGRANT_CONTROLLER_NAME, '--port', local_disk[:port], '--device', 0, '--type', 'hdd', '--medium', local_disk_filename]
  #     end
  #   end
  # end

  # # cleanup after "destroy" action
  # config.trigger.after :destroy do |trigger|
  #   trigger.name = "Cleanup operation"
  #   trigger.ruby do
  #     # the following loop is now obsolete as these files will be removed automatically as machine dependency
  #     local_disks.each do |local_disk|
  #       local_disk_filename = File.join(disks_directory, "#{local_disk[:filename]}.vdi")
  #       if File.exist?(local_disk_filename)
  #         puts "Deleting \"#{local_disk[:filename]}\" disk"
  #         system("vboxmanage closemedium disk #{local_disk_filename} --delete")
  #       end
  #     end
  #     if File.exist?(disks_directory)
  #       FileUtils.rmdir(disks_directory)
  #     end
  #   end
  # end
  # # END DISKS CREATION
  # ###################
  # config.vm.disk :disk, size: "5GB", name: "extdisk-01"
  # config.vm.disk :disk, size: "5GB", name: "extdisk-02"
  # config.vm.synced_folder "/media/emp-06/emp-04-d2/extr-vagrant-disk/", "/glustervolume/"
  config.ssh.insert_key = false
  config.vm.synced_folder ".", "/vagrant", disabled: true
  zone="12"
  # setup devops user
  config.vm.provision "file", source: "../shared-files/remove_devops.sh", destination: "remove_devops.sh"
  config.vm.provision "file", source: "../shared-files/reset_environment.sh", destination: "reset_environment.sh"
  config.vm.provision "file", source: "../shared-files/setup_initial_user.sh", destination: "setup_initial_user.sh"
  config.vm.provision "file", source: "../shared-files/init_cluster.js", destination: "init_cluster.js"
  config.vm.provision "file", source: "../shared-files/build_cluster.js", destination: "build_cluster.js"
  config.vm.provision :shell, :inline => "sudo sh setup_initial_user.sh"
#   config.vm.provision "shell", inline: "sudo apt-get update; sudo ln -sf /usr/bin/python3 /usr/bin/python"
#   config.vm.provision "ansible" do |ans| 
#     ans.playbook = "setup_initial_user.yaml"
#     ans.inventory_path = "hosts.ini"
#   end
  # network setup
  config.vm.network "public_network", auto_config: true
  config.vm.network "forwarded_port", guest: 8443, host: 8443, auto_correct: true
  config.vm.synced_folder "shared/", "/shared/dir1", create: true
  config.vm.provider :virtualbox do |v|
    v.memory = 2048
    v.linked_clone = true
  end
<<<<<<< HEAD

  # config.vm.provision :shell, :inline => "DEBIAN_FRONTEND=noninteractive sed -i '1i192.168.0.131  cd-#{zone}-131' /etc/hosts", :privileged => true
  # config.vm.provision :shell, :inline => "DEBIAN_FRONTEND=noninteractive sed -i '1i192.168.0.132  cd-#{zone}-132' /etc/hosts", :privileged => true
  # config.vm.provision :shell, :inline => "DEBIAN_FRONTEND=noninteractive sed -i '1i192.168.0.133  cd-#{zone}-133' /etc/hosts", :privileged => true

=======
<<<<<<< HEAD
>>>>>>> e4b8fd68c84fb759336cd6be1f28493523bfcb8d
  (131..133).each do |i|
=======
  (166..170).each do |i|
>>>>>>> c166590 (update cd-ansible vagrantfile)
    config.vm.define "cd-#{zone}-#{i}" do |app|
      # sync folder to host
      # config.vm.synced_folder "/media/emp-06/emp-04-d2/emp-06-gluster-#{i}/", "/glustervolume/"
      app.vm.hostname = "cd-#{zone}-#{i}"
      app.vm.network :public_network, ip: "192.168.0.#{i}"

      # config.vm.provision :shell, :inline => "apt update && sudo apt upgrade -y", :privileged => true
      # config.vm.provision :shell, :inline => "DEBIAN_FRONTEND=noninteractive apt install fish net-tools glusterfs-server -y", :privileged => true
      # config.vm.provision :shell, :inline => "DEBIAN_FRONTEND=noninteractive systemctl start glusterd", :privileged => true
      # config.vm.provision :shell, :inline => "DEBIAN_FRONTEND=noninteractive systemctl enable glusterd", :privileged => true

      # config.vm.provision :shell, :inline => "DEBIAN_FRONTEND=noninteractive mkdir -p /glusterfs/distributed", :privileged => true
      
    end
  end

  # post installation on server1
  # (131..133).each do |i|
  #   config.vm.define "cd-#{zone}-#{i}" do |app|
  #     if (i == 131) then
  #       # config.vm.provision :shell, :inline => "DEBIAN_FRONTEND=noninteractive gluster peer probe cd-#{zone}-132", :privileged => true
  #       # config.vm.provision :shell, :inline => "DEBIAN_FRONTEND=noninteractive gluster peer probe cd-#{zone}-133", :privileged => true
  #     end
  #   end
  # end

  (134..135).each do |i|
    config.vm.define "cd-#{zone}-#{i}" do |app|
      app.vm.hostname = "cd-#{zone}-#{i}"
      app.vm.network :public_network, ip: "192.168.0.#{i}"
      

      # config.vm.provision :shell, :inline => "DEBIAN_FRONTEND=noninteractive sudo apt update && sudo apt upgrade -y", :privileged => true
      # config.vm.provision :shell, :inline => "DEBIAN_FRONTEND=noninteractive sudo apt install glusterfs-client -y", :privileged => true
      # config.vm.provision :shell, :inline => "DEBIAN_FRONTEND=noninteractive sudo mkdir -p /mnt/glusterfs", :privileged => true
    end
  end
  
  
end
